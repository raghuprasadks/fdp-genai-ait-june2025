pip install tensorflow
pip install cohere
pip install diffusers transformers torch
https://ai.google.dev/gemini-api/docs/quickstart
pip install --upgrade google-generativeai
https://nnfs.io/bkr/
https://nnfs.io/neural_network_animations
https://medium.com/@nghihuynh_37300/understanding-loss-functions-for-classification-81c19ee72c2a
https://playground.tensorflow.org/
https://poloclub.github.io/transformer-explainer/

https://www.datacamp.com/tutorial/loss-function-in-machine-learning
https://www.geeksforgeeks.org/machine-learning/activation-functions-neural-networks/
https://www.sarvam.ai/blogs/indias-sovereign-llm
https://docs.sarvam.ai/api-reference-docs/cookbook/starter-notebooks/stt-api-tutorial

https://huggingface.co/welcome
https://huggingface.co/docs/smolagents/index

https://huggingface.co/tasks/text-generation
inference provider

step 1 - unzip huggingfacehub folder
step 2 - unzip frontend folder
step 3 - cd to huggingfacehub
install following libraries
pip install flask flask-cors huggingface-hub
python app.py

your back end will be running

step 4 - unzip frontend
open chatbot.html in the browser
start chatting..
happy chatting





pip install flask-cors

import os
from huggingface_hub import InferenceClient

client = InferenceClient(
    provider="nebius",
    api_key=os.environ["HF_TOKEN"],
)

completion = client.chat.completions.create(
    model="mistralai/Mistral-Nemo-Instruct-2407",
    messages=[
        {
            "role": "user",
            "content": "What is the capital of France?"
        }
    ],
)

print(completion.choices[0].message)